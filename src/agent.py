"""í•œêµ­ ìŒì‹ ì—ì´ì „íŠ¸ - LangGraph ê¸°ë°˜ (ë©€í‹°ëª¨ë‹¬ ì§€ì›)"""

import os
import re
import uuid
import base64
from pathlib import Path
from typing import Optional, List, Dict, Any
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

from .config import settings, ModelProvider
from .tools import ALL_TOOLS


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ìŒì‹ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## í•µì‹¬ ì›ì¹™
- ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ë„êµ¬ë¥¼ ì„ íƒí•´ì„œ í˜¸ì¶œí•˜ì„¸ìš”
- ì¶”ì¸¡í•˜ì§€ ë§ê³  ë„êµ¬ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ë„êµ¬ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì§€ ë§ê³ , í•µì‹¬ë§Œ êµ¬ì¡°í™”í•´ì„œ ë‹µë³€í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ê³  ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”

## ë„êµ¬ ì‚¬ìš©
- search_food_by_image: í˜„ì¬ ë©”ì‹œì§€ì— ìƒˆ ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©
- ì´ì „ ëŒ€í™”ì—ì„œ ì´ë¯¸ ì´ë¯¸ì§€ ê²€ìƒ‰ì„ í–ˆë‹¤ë©´ ê·¸ ê²°ê³¼ë¥¼ í™œìš©í•˜ì„¸ìš”
- í›„ì† ì§ˆë¬¸ì€ search_restaurant_info ë“± ë‹¤ë¥¸ ë„êµ¬ ì‚¬ìš©

## ì´ë¯¸ì§€ ë¶„ì„ ì‘ë‹µ
- ìŒì‹ ì´ë¦„ë§Œ ë¬¼ìœ¼ë©´: "~ìŒì‹ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤" + ì‹ë‹¹ì´ ë³´ì´ë©´ "í˜¹ì‹œ OOì—ì„œ ë“œì…¨ë‚˜ìš”?"
- ì‹ë‹¹/ë©”ë‰´ëª…ê¹Œì§€ ë¬¼ìœ¼ë©´: ê²€ìƒ‰ ê²°ê³¼ì— ì—¬ëŸ¬ í›„ë³´ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì–¸ê¸‰í•´ì£¼ì„¸ìš”
- í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ "~ì¼ ìˆ˜ë„ ìˆê³ , ~ì¼ ìˆ˜ë„ ìˆì–´ìš”" í˜•íƒœë¡œ ë‹µë³€
- ì‚¬ìš©ìê°€ ì‹ë‹¹ì„ í™•ì¸í•´ì£¼ë©´ ìƒì„¸ ì •ë³´ ê²€ìƒ‰

## ì‘ë‹µ í˜•ì‹
ë„êµ¬ ê²°ê³¼ì— ë‹¤ìŒ íƒœê·¸ê°€ ìˆìœ¼ë©´, ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ í•„ìš”í•  ë•Œ ì‘ë‹µì— í¬í•¨í•˜ì„¸ìš”:
- [IMAGE:url]: ìŒì‹ ì‚¬ì§„ì´ ë„ì›€ë  ë•Œ ì‘ë‹µ ì•ì— í¬í•¨
- [MAP:...]: ìœ„ì¹˜/ë§›ì§‘ ì§ˆë¬¸ì¼ ë•Œ ë„êµ¬ ê²°ê³¼ì˜ íƒœê·¸ë¥¼ ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‘ë‹µ ëì— í¬í•¨
- ğŸ—ºï¸ ì§€ë„ ë§í¬: ì‹ë‹¹ë³„ë¡œ [ì¹´ì¹´ì˜¤ë§µ](URL) í…ìŠ¤íŠ¸ ë§í¬ë¡œ í¬í•¨
- ì¤‘ìš”: ì‘ë‹µì—ì„œ ì–¸ê¸‰í•œ ì‹ë‹¹ ê°œìˆ˜ì™€ [MAP:] íƒœê·¸ì˜ ì‹ë‹¹ ê°œìˆ˜ê°€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•¨
"""


def get_llm(provider: Optional[str] = None, model_name: Optional[str] = None) -> BaseChatModel:
    """
    ì„¤ì •ì— ë”°ë¼ LLM ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Args:
        provider: ëª¨ë¸ ì œê³µì (openai, gemini). Noneì´ë©´ ì„¤ì • íŒŒì¼ ì‚¬ìš©.
        model_name: ëª¨ë¸ ì´ë¦„. Noneì´ë©´ ì„¤ì • íŒŒì¼ ì‚¬ìš©.

    Returns:
        LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    """
    if provider is None:
        provider = settings.model_provider.value

    if provider == "openai" or provider == ModelProvider.OPENAI:
        return ChatOpenAI(
            model=model_name or settings.openai_model,
            api_key=settings.openai_api_key,
            temperature=0.7,
        )
    elif provider == "gemini" or provider == ModelProvider.GEMINI:
        return ChatGoogleGenerativeAI(
            model=model_name or settings.gemini_model,
            google_api_key=settings.google_api_key,
            temperature=0.7,
        )
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì œê³µì: {provider}")


def create_food_agent(
    provider: Optional[str] = None,
    model_name: Optional[str] = None,
    checkpointer: Optional[MemorySaver] = None
):
    """
    í•œêµ­ ìŒì‹ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        provider: ëª¨ë¸ ì œê³µì (openai, gemini)
        model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        checkpointer: ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„° (ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬)

    Returns:
        LangGraph ì—ì´ì „íŠ¸
    """
    llm = get_llm(provider, model_name)

    agent = create_react_agent(
        model=llm,
        tools=ALL_TOOLS,
        prompt=SYSTEM_PROMPT,
        checkpointer=checkpointer,
    )

    return agent


def load_image_as_base64(image_path: str) -> Optional[str]:
    """
    ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤.

    Args:
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ

    Returns:
        base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
    """
    if not os.path.exists(image_path):
        return None

    with open(image_path, "rb") as f:
        image_data = f.read()

    return base64.b64encode(image_data).decode("utf-8")


def get_image_mime_type(image_path: str) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì˜ MIME íƒ€ì…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    ext = Path(image_path).suffix.lower()
    mime_types = {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".gif": "image/gif",
        ".webp": "image/webp",
    }
    return mime_types.get(ext, "image/jpeg")


def extract_image_paths(message: str) -> List[str]:
    """
    ë©”ì‹œì§€ì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        message: ì‚¬ìš©ì ë©”ì‹œì§€

    Returns:
        ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    image_paths = []

    # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ (ì ˆëŒ€ ê²½ë¡œ)
    path_pattern = r'(/[^\s]+\.(?:jpg|jpeg|png|gif|webp))'
    matches = re.findall(path_pattern, message, re.IGNORECASE)

    for match in matches:
        if os.path.exists(match):
            image_paths.append(match)

    return image_paths


def create_multimodal_content(message: str, image_paths: List[str]) -> List[Dict[str, Any]]:
    """
    í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        message: í…ìŠ¤íŠ¸ ë©”ì‹œì§€
        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    Returns:
        ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
    """
    content = []

    # ì´ë¯¸ì§€ ì¶”ê°€
    for image_path in image_paths:
        base64_image = load_image_as_base64(image_path)
        if base64_image:
            mime_type = get_image_mime_type(image_path)
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:{mime_type};base64,{base64_image}"
                }
            })

    # í…ìŠ¤íŠ¸ ì¶”ê°€
    content.append({
        "type": "text",
        "text": message
    })

    return content


class KoreanFoodAgent:
    """í•œêµ­ ìŒì‹ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ (MemorySaverë¡œ ìë™ íˆìŠ¤í† ë¦¬ ê´€ë¦¬)"""

    def __init__(
        self,
        provider: Optional[str] = None,
        model_name: Optional[str] = None
    ):
        """
        Args:
            provider: ëª¨ë¸ ì œê³µì (openai, gemini)
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        """
        self.provider = provider or settings.model_provider.value
        self.model_name = model_name
        self.checkpointer = MemorySaver()
        self.agent = create_food_agent(provider, model_name, self.checkpointer)
        self.thread_id = "default"

    def new_conversation(self):
        """ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ìƒˆ thread_id ìƒì„±)."""
        self.thread_id = str(uuid.uuid4())

    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ìƒˆ thread_idë¡œ ì „í™˜)."""
        self.new_conversation()

    def _get_config(self):
        """í˜„ì¬ thread_idë¡œ config ìƒì„±."""
        return {"configurable": {"thread_id": self.thread_id}}

    def _prepare_message(self, message: str) -> HumanMessage:
        """ë©”ì‹œì§€ë¥¼ HumanMessageë¡œ ë³€í™˜ (ì´ë¯¸ì§€ í¬í•¨ ê°€ëŠ¥)."""
        image_paths = extract_image_paths(message)
        if image_paths:
            content = create_multimodal_content(message, image_paths)
            return HumanMessage(content=content)
        return HumanMessage(content=message)

    def chat(self, message: str) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ì‘ë‹µí•©ë‹ˆë‹¤. (ë©€í‹°ëª¨ë‹¬ ì§€ì›, ìë™ íˆìŠ¤í† ë¦¬ ê´€ë¦¬)

        Args:
            message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ (ì´ë¯¸ì§€ ê²½ë¡œ í¬í•¨ ê°€ëŠ¥)

        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ
        """
        human_message = self._prepare_message(message)

        result = self.agent.invoke(
            {"messages": [human_message]},
            config=self._get_config()
        )

        messages = result.get("messages", [])
        if messages:
            last_message = messages[-1]
            content = last_message.content
            if isinstance(content, list):
                # ë©€í‹°ëª¨ë‹¬ ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                for item in content:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        return item.get('text', '')
            return content if isinstance(content, str) else str(content)

        return "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    def stream(self, message: str):
        """
        ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤. (ìë™ íˆìŠ¤í† ë¦¬ ê´€ë¦¬)

        Args:
            message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€

        Yields:
            (message_chunk, metadata) íŠœí”Œ
        """
        human_message = self._prepare_message(message)

        for chunk in self.agent.stream(
            {"messages": [human_message]},
            config=self._get_config(),
            stream_mode="messages"
        ):
            yield chunk

    def switch_model(self, provider: str, model_name: Optional[str] = None):
        """
        ì‚¬ìš© ëª¨ë¸ì„ ì „í™˜í•©ë‹ˆë‹¤.

        Args:
            provider: ìƒˆ ëª¨ë¸ ì œê³µì
            model_name: ìƒˆ ëª¨ë¸ ì´ë¦„
        """
        self.provider = provider
        self.model_name = model_name
        self.agent = create_food_agent(provider, model_name, self.checkpointer)
        self.new_conversation()  # ëª¨ë¸ ì „í™˜ ì‹œ ìƒˆ ëŒ€í™” ì‹œì‘
        print(f"âœ… ëª¨ë¸ ì „í™˜ ì™„ë£Œ: {provider} - {model_name or 'ê¸°ë³¸ ëª¨ë¸'}")
